{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fwkxPaZaMFv"
   },
   "source": [
    "# **Deep Reinforcement Learning Class Spring 2025 Assignment 1**\n",
    "\n",
    "In this assignment, we will learn about gym interface, gridworld, q-learning, and etc. You will need to fill in the missing code snippets (marked by TODO).\n",
    "\n",
    "Make a copy of this notebook using File > Save a copy in Drive and edit it with your answers.\n",
    "\n",
    "WARNING: Do not put your name or any other personal identification information in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gym in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gym) (2.1.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gym) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gym) (0.0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\yuhun\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting numpy==1.24.0\n",
      "  Using cached numpy-1.24.0.tar.gz (10.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\yuhun\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 105, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 96, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 67, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\commands\\install.py\", line 379, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 95, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 397, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 174, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 162, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "                       ^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 53, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 187, in _make_candidate_from_link\n",
      "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 233, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in __init__\n",
      "    super().__init__(\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 159, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 236, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 315, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 527, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 642, in _prepare_linked_requirement\n",
      "    dist = _get_prepared_distribution(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 72, in _get_prepared_distribution\n",
      "    abstract_dist.prepare_distribution_metadata(\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 56, in prepare_distribution_metadata\n",
      "    self._install_build_reqs(finder)\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 126, in _install_build_reqs\n",
      "    build_reqs = self._get_build_requires_wheel()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\distributions\\sdist.py\", line 103, in _get_build_requires_wheel\n",
      "    return backend.get_requires_for_build_wheel()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_internal\\utils\\misc.py\", line 701, in get_requires_for_build_wheel\n",
      "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 166, in get_requires_for_build_wheel\n",
      "    return self._call_hook('get_requires_for_build_wheel', {\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_impl.py\", line 321, in _call_hook\n",
      "    raise BackendUnavailable(data.get('traceback', ''))\n",
      "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 77, in _build_backend\n",
      "    obj = import_module(mod_path)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2544.0_x64__qbz5n2kfra8p0\\Lib\\importlib\\__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\yuhun\\AppData\\Local\\Temp\\pip-build-env-_0999d_e\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 10, in <module>\n",
      "    import distutils.core\n",
      "ModuleNotFoundError: No module named 'distutils'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (4.66.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\yuhun\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Users\\yuhun\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym\n",
    "!pip install numpy==1.24.0\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "L8nLFy4z2bZh"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import importlib.util\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "W_kyHQESMG0E"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "suK5e6_R2Fcq"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This environment allows you to verify whether your program runs correctly during testing,\n",
    "# as it follows the same observation format from `env.reset()` and `env.step()`.\n",
    "# However, keep in mind that this is just a simplified environment.\n",
    "# The full specifications for the real testing environment can be found in the provided spec.\n",
    "#\n",
    "# You are free to modify this file to better match the real environment and train your own agent.\n",
    "# Good luck!\n",
    "\n",
    "\n",
    "class SimpleTaxiEnv(gym.Env):\n",
    "    def __init__(self, grid_size=10, fuel_limit=5000):\n",
    "        \"\"\"\n",
    "        Custom Taxi environment supporting different grid sizes.\n",
    "        \"\"\"\n",
    "        self.grid_size = grid_size\n",
    "        self.fuel_limit = fuel_limit\n",
    "        self.current_fuel = fuel_limit\n",
    "        self.passenger_picked_up = False\n",
    "\n",
    "        self.stations = [(0, 0), (0, self.grid_size - 1), (self.grid_size - 1, 0), (self.grid_size - 1, self.grid_size - 1)]\n",
    "        self.passenger_loc = None\n",
    "\n",
    "        self.obstacles = set()  # No obstacles in simple version\n",
    "        self.destination = None\n",
    "    def legal(self):\n",
    "      available_positions = [\n",
    "            (x, y) for x in range(self.grid_size) for y in range(self.grid_size)\n",
    "            if (x, y) not in self.obstacles\n",
    "      ]\n",
    "      n=len(available_positions)\n",
    "      p = [0 for i in range(n)]\n",
    "      global group_size\n",
    "      group_size = n\n",
    "      def find_parent(x):\n",
    "        if x!=p[x]:\n",
    "          p[x]=find_parent(p[x])\n",
    "        return p[x]\n",
    "      def Union(a,b):\n",
    "        global group_size\n",
    "        a=find_parent(a)\n",
    "        b=find_parent(b)\n",
    "        if a!=b:\n",
    "          group_size -= 1\n",
    "          if np.random.randint(2)==0:\n",
    "            p[a]=b\n",
    "          else:\n",
    "            p[b]=a\n",
    "      for i in range(n):\n",
    "        p[i]=i\n",
    "      for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "          if abs(available_positions[i][0]-available_positions[j][0])+abs(available_positions[i][1]-available_positions[j][1])==1:\n",
    "            Union(i,j)\n",
    "      return group_size==1\n",
    "    def reset(self,grid_size=None,obstacle_len=None):\n",
    "        \"\"\"Reset the environment, ensuring Taxi, passenger, and destination are not overlapping obstacles\"\"\"\n",
    "        self.current_fuel = self.fuel_limit\n",
    "        self.passenger_picked_up = False\n",
    "        if grid_size == None:\n",
    "            grid_size = np.random.randint(5,11)\n",
    "        self.grid_size = grid_size\n",
    "        self.stations = []\n",
    "        if obstacle_len == None:\n",
    "            obstacle_len = np.random.randint(0,grid_size*grid_size)\n",
    "        while len(self.stations)<4:\n",
    "            posx,posy = np.random.randint(0,self.grid_size),np.random.randint(0,self.grid_size)\n",
    "            # check posx,posy is not adjacent to existed stations\n",
    "            if not any([abs(posx-station[0])+abs(posy-station[1])<=1 for station in self.stations]):\n",
    "                self.stations.append((posx,posy))\n",
    "        #self.stations = [(0, 0), (0, self.grid_size - 1), (self.grid_size - 1, 0), (self.grid_size - 1, self.grid_size - 1)]\n",
    "        self.obstacles = set()\n",
    "        cnt = 0\n",
    "        while len(self.obstacles)<obstacle_len and cnt < self.grid_size*self.grid_size*10:\n",
    "            posx,posy = np.random.randint(0,self.grid_size),np.random.randint(0,self.grid_size)\n",
    "            if (posx,posy) not in self.stations and (posx,posy) not in self.obstacles:\n",
    "                self.obstacles.add((posx,posy))\n",
    "            if not self.legal():\n",
    "                self.obstacles.remove((posx,posy))\n",
    "            cnt = cnt +1\n",
    "        available_positions = [\n",
    "            (x, y) for x in range(self.grid_size) for y in range(self.grid_size)\n",
    "            if (x, y) not in self.stations and (x, y) not in self.obstacles\n",
    "        ]\n",
    "\n",
    "        self.taxi_pos = random.choice(available_positions)\n",
    "\n",
    "        self.passenger_loc = random.choice([pos for pos in self.stations])\n",
    "\n",
    "\n",
    "        possible_destinations = [s for s in self.stations if s != self.passenger_loc]\n",
    "        self.destination = random.choice(possible_destinations)\n",
    "        #print(f'grid size : {self.grid_size}, obstacles : {len(self.obstacles)}, ')\n",
    "        #self.render_env(self.taxi_pos)\n",
    "        return self.get_state(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Perform an action and update the environment state.\"\"\"\n",
    "        taxi_row, taxi_col = self.taxi_pos\n",
    "        next_row, next_col = taxi_row, taxi_col\n",
    "        reward = 0\n",
    "        if action == 0 :  # Move Down\n",
    "            next_row += 1\n",
    "        elif action == 1:  # Move Up\n",
    "            next_row -= 1\n",
    "        elif action == 2:  # Move Right\n",
    "            next_col += 1\n",
    "        elif action == 3:  # Move Left\n",
    "            next_col -= 1\n",
    "\n",
    "\n",
    "        if action in [0, 1, 2, 3]:  # Only movement actions should be checked\n",
    "            if (next_row, next_col) in self.obstacles or not (0 <= next_row < self.grid_size and 0 <= next_col < self.grid_size):\n",
    "                reward -=10\n",
    "                #print('block')\n",
    "            else:\n",
    "                self.taxi_pos = (next_row, next_col)\n",
    "                if self.passenger_picked_up:\n",
    "                    self.passenger_loc = self.taxi_pos\n",
    "        else:\n",
    "            if action == 4:  # PICKUP\n",
    "                if self.taxi_pos == self.passenger_loc:\n",
    "                    self.passenger_picked_up = True\n",
    "                    self.passenger_loc = self.taxi_pos\n",
    "                else:\n",
    "                    reward = -10\n",
    "            elif action == 5:  # DROPOFF\n",
    "                if self.passenger_picked_up:\n",
    "                    self.passenger_picked_up = False\n",
    "                    self.passenger_loc = self.taxi_pos\n",
    "                    if self.taxi_pos == self.destination:\n",
    "                        reward += 50\n",
    "                        return self.get_state(), reward -0.1, True, {}\n",
    "                    else:\n",
    "                        reward -=10\n",
    "                else:\n",
    "                    reward -=10\n",
    "\n",
    "        reward -= 0.1\n",
    "\n",
    "        self.current_fuel -= 1\n",
    "        if self.current_fuel <= 0:\n",
    "            return self.get_state(), reward -10, True, {}\n",
    "\n",
    "\n",
    "\n",
    "        return self.get_state(), reward, False, {}\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"Return the current environment state.\"\"\"\n",
    "        taxi_row, taxi_col = self.taxi_pos\n",
    "        passenger_row, passenger_col = self.passenger_loc\n",
    "        destination_row, destination_col = self.destination\n",
    "\n",
    "        obstacle_north = int(taxi_row == 0 or (taxi_row-1, taxi_col) in self.obstacles)\n",
    "        obstacle_south = int(taxi_row == self.grid_size - 1 or (taxi_row+1, taxi_col) in self.obstacles)\n",
    "        obstacle_east  = int(taxi_col == self.grid_size - 1 or (taxi_row, taxi_col+1) in self.obstacles)\n",
    "        obstacle_west  = int(taxi_col == 0 or (taxi_row , taxi_col-1) in self.obstacles)\n",
    "\n",
    "        passenger_loc_north = int((taxi_row - 1, taxi_col) == self.passenger_loc)\n",
    "        passenger_loc_south = int((taxi_row + 1, taxi_col) == self.passenger_loc)\n",
    "        passenger_loc_east  = int((taxi_row, taxi_col + 1) == self.passenger_loc)\n",
    "        passenger_loc_west  = int((taxi_row, taxi_col - 1) == self.passenger_loc)\n",
    "        passenger_loc_middle  = int( (taxi_row, taxi_col) == self.passenger_loc)\n",
    "        passenger_look = passenger_loc_north or passenger_loc_south or passenger_loc_east or passenger_loc_west or passenger_loc_middle\n",
    "\n",
    "        destination_loc_north = int( (taxi_row - 1, taxi_col) == self.destination)\n",
    "        destination_loc_south = int( (taxi_row + 1, taxi_col) == self.destination)\n",
    "        destination_loc_east  = int( (taxi_row, taxi_col + 1) == self.destination)\n",
    "        destination_loc_west  = int( (taxi_row, taxi_col - 1) == self.destination)\n",
    "        destination_loc_middle  = int( (taxi_row, taxi_col) == self.destination)\n",
    "        destination_look = destination_loc_north or destination_loc_south or destination_loc_east or destination_loc_west or destination_loc_middle\n",
    "\n",
    "\n",
    "        state = (taxi_row, taxi_col, self.stations[0][0],self.stations[0][1] ,self.stations[1][0],self.stations[1][1],self.stations[2][0],self.stations[2][1],self.stations[3][0],self.stations[3][1],obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look)\n",
    "        return state,self.passenger_picked_up,self.passenger_loc\n",
    "    def render_env(self, taxi_pos,   action=None, step=None, fuel=None):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        grid = [['.'] * self.grid_size for _ in range(self.grid_size)]\n",
    "\n",
    "        '''\n",
    "        # Place passenger\n",
    "        py, px = passenger_pos\n",
    "        if 0 <= px < self.grid_size and 0 <= py < self.grid_size:\n",
    "            grid[py][px] = 'P'\n",
    "        '''\n",
    "        stations_char =['R','G','B','Y']\n",
    "        for i in range(len(self.stations)):\n",
    "            sx,sy = self.stations[i]\n",
    "            grid[sy][sx] = stations_char[i]\n",
    "        for ox,oy in self.obstacles:\n",
    "            grid[oy][ox] = '#'\n",
    "\n",
    "        '''\n",
    "        # Place destination\n",
    "        dy, dx = destination_pos\n",
    "        if 0 <= dx < self.grid_size and 0 <= dy < self.grid_size:\n",
    "            grid[dy][dx] = 'D'\n",
    "        '''\n",
    "        # Place taxi\n",
    "        ty, tx = taxi_pos\n",
    "        if 0 <= tx < self.grid_size and 0 <= ty < self.grid_size:\n",
    "            grid[ty][tx] = '🚖'\n",
    "\n",
    "        # Print step info\n",
    "        print(f\"\\nStep: {step}\")\n",
    "        print(f\"Taxi Position: ({tx}, {ty})\")\n",
    "        #print(f\"Passenger Position: ({px}, {py}) {'(In Taxi)' if (px, py) == (tx, ty) else ''}\")\n",
    "        #print(f\"Destination: ({dx}, {dy})\")\n",
    "        print(f\"Fuel Left: {fuel}\")\n",
    "        print(f\"Last Action: {self.get_action_name(action)}\\n\")\n",
    "\n",
    "        # Print grid\n",
    "        for row in grid:\n",
    "            print(\" \".join(row))\n",
    "        print(\"\\n\")\n",
    "\n",
    "    def get_action_name(self, action):\n",
    "        \"\"\"Returns a human-readable action name.\"\"\"\n",
    "        actions = [\"Move South\", \"Move North\", \"Move East\", \"Move West\", \"Pick Up\", \"Drop Off\"]\n",
    "        return actions[action] if action is not None else \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "henzhTux2qUO"
   },
   "source": [
    "## 狀態定義\n",
    "\n",
    "## 狀態定義\n",
    "\n",
    "- pos (相對 R/G/Y/B)的距離 (用 +-0)去代表，直到走到一位置確認是否 pickup/destination為止後 random 換位置。\n",
    "    - 只要相對位移>0一律用 +1表示, <0 用 -1\n",
    "- obstacles\n",
    "- passenger state\n",
    "    - 0 ⇒ not on car\n",
    "    - 1 ⇒ on car\n",
    "- candidates_p\n",
    "    - original : stations\n",
    "    - whenever one is not worked ⇒ removed it\n",
    "- mask_p= [1] * len(candidates_p) + [0] * (4-len(candidates_p))\n",
    "    - 0 代表 passenger_i 是不可能的位置\n",
    "    - 1 代表可能\n",
    "- candidates_goal\n",
    "    - original : stations\n",
    "    - whenever one is not goal ⇒ removed it\n",
    "- mask_goal= [1] * len(candidates_goal) + [0] * (4-len(candidates_goal))\n",
    "    - 0 代表 passenger_i 是不可能的位置\n",
    "    - 1 代表可能\n",
    "- pickup\n",
    "- goal_id : {0,1,2,3}\n",
    "    - 目標是 stations[goal_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKN9Ot4BpJZM"
   },
   "source": [
    "### 轉移\n",
    "\n",
    "- relative_pos = (0,0)\n",
    "    - if passenger_look\n",
    "        - candidate_p = [pos]\n",
    "        - success pickup\n",
    "            - success pickup ⇒ pickup_id=True\n",
    "            - candidates_p = [pos]\n",
    "            - goal = random choice (candidates_goal)\n",
    "    - else:\n",
    "        - candidate_p remove pos\n",
    "        - goal = random.choice(candidates_p)\n",
    "    - if goal_look\n",
    "        - candidate_g = [pos]\n",
    "    - else:\n",
    "        - candidate_g.remove(pos)\n",
    "        - goal = random choice (candidates_goal)\n",
    "- drop\n",
    "    - if pickup ⇒ candidates_p = [pos], goal_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vDSsEzx-2ndf"
   },
   "outputs": [],
   "source": [
    "from re import M\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "def tabular_q_learning(env,episodes=5000, alpha=0.1, gamma=0.99,\n",
    "                       epsilon_start=1.0, epsilon_end=0.1, decay_rate=0.9995):\n",
    "\n",
    "    global stations, candidates_p,candidates_goal, pickup\n",
    "    stations = [[0,0] for _ in range(4)]\n",
    "    candidates_p = [i for i in stations]\n",
    "    candidates_goal = [i for i in stations]\n",
    "    pickup=False\n",
    "    action_size = 6\n",
    "    q_table = defaultdict(lambda :np.zeros(action_size))\n",
    "    pickup_id = 4\n",
    "    drop_id = 5\n",
    "    ifpickup=False\n",
    "    p_loc = (0,0)\n",
    "    def cmp(a,b):\n",
    "        if a==b:\n",
    "            return 0\n",
    "        return 1 if a<b else -1\n",
    "    def get_state_obs(obs,action,last_action=None):\n",
    "        global stations,pickup,candidates_p,candidates_goal\n",
    "        #print(candidates_p)\n",
    "        taxi_row, taxi_col, stations[0][0], stations[0][1] , stations[1][0], stations[1][1],stations[2][0],stations[2][1],stations[3][0],stations[3][1],obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = obs\n",
    "        agent_pos = (taxi_row,taxi_col)\n",
    "        if action==None:\n",
    "            # initialize\n",
    "            candidates_goal = [tuple(i) for i in stations]\n",
    "            candidates_p = [tuple(i) for i in stations]\n",
    "            pickup=False\n",
    "        if passenger_look:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        else:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        if destination_look:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        else:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        if action==pickup_id and not pickup and agent_pos in candidates_p:\n",
    "            pickup = True\n",
    "            candidates_p = []\n",
    "        elif action == drop_id and pickup:\n",
    "            pickup=False\n",
    "            candidates_p.append(agent_pos)\n",
    "        cmp_pos = (0,0)\n",
    "        if not pickup:\n",
    "            # choose the one that is closest to the agent\n",
    "            idx = np.argmin([abs(agent_pos[0]-i[0])+abs(agent_pos[1]-i[1]) for i in candidates_p])\n",
    "            cmp_pos = candidates_p[idx]\n",
    "        else:\n",
    "            # choose the one that is closest to the agent\n",
    "            idx = np.argmin([abs(agent_pos[0]-i[0])+abs(agent_pos[1]-i[1]) for i in candidates_goal])\n",
    "            cmp_pos = candidates_goal[idx]\n",
    "        passenger_look = passenger_look and agent_pos in candidates_p\n",
    "        destination_look = destination_look and agent_pos in candidates_goal\n",
    "        real_look = passenger_look if not pickup else destination_look\n",
    "        relative_pos = (cmp(agent_pos[0],cmp_pos[0]),cmp(agent_pos[1],cmp_pos[1]))\n",
    "        return (relative_pos,pickup, real_look, (obstacle_north,obstacle_south,obstacle_east,obstacle_west),last_action)\n",
    "    \"\"\"\n",
    "    if action == 0 :  # Move Down\n",
    "        next_row += 1\n",
    "    elif action == 1:  # Move Up\n",
    "        next_row -= 1\n",
    "    elif action == 2:  # Move Right\n",
    "        next_col += 1\n",
    "    elif action == 3:  # Move Left\n",
    "        next_col -= 1\n",
    "    \"\"\"\n",
    "    station_size = 4\n",
    "    total_reward = 0\n",
    "    total_reward_shaped = 0\n",
    "    cnt = [0,0,0,0]\n",
    "    epsilon = epsilon_start\n",
    "    averaged = [0,0]\n",
    "    batch_size = 100\n",
    "    for epoch in tqdm(range(episodes+batch_size)):\n",
    "        if epoch >=episodes:\n",
    "            epsilon = 0\n",
    "        grid_size = 5 #np.random.randint(5,11)\n",
    "        obstacle_size = np.random.randint(grid_size*grid_size)\n",
    "        obs,_ = env.reset(grid_size,obstacle_size)\n",
    "        averaged[0]+=env.grid_size\n",
    "        averaged[1]+=len(env.obstacles)\n",
    "        obs,ifpickup,p_loc = obs\n",
    "        done = False\n",
    "        state = get_state_obs(obs,action=None)\n",
    "        steps=0\n",
    "        action_l=[]\n",
    "        success = False\n",
    "        has_pickup=False\n",
    "\n",
    "        while not done:\n",
    "            \"\"\"if state[-1]!=(0,0,0,0):\n",
    "              print(state[-1])\"\"\"\n",
    "            if np.random.choice(2,p=[epsilon,1-epsilon])==0 or state not in q_table.keys():\n",
    "                action = np.random.randint(6)\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "            lst_pickup = pickup\n",
    "            \n",
    "            relative_pos,pickup, _ , _,last_action = state\n",
    "            obs,reward,done,_ = env.step(action)\n",
    "            obs,ifpickup,p_loc = obs\n",
    "            if action in [0,1,2,3]:\n",
    "                next_state = get_state_obs(obs,action,action)\n",
    "            else:\n",
    "                next_state = get_state_obs(obs,action,last_action)\n",
    "            total_reward += reward\n",
    "\n",
    "            ### reward shaping\n",
    "            reward_shaping = 0\n",
    "            \"\"\"if relative_pos == (0,0):\n",
    "                # want it to go to possible goal\n",
    "                #reward_shaping += 0.5\"\"\"\n",
    "            if relative_pos != (0,0) and action in [pickup_id,drop_id]:\n",
    "                reward_shaping -= 10\n",
    "            if done and reward>0:\n",
    "                cnt[2]+=1\n",
    "            \n",
    "            relative_pos,pickup, _ , _,_ = next_state\n",
    "            if not done and reward <-10 and action in [0,1,2,3]:\n",
    "                #print('hit wall')\n",
    "                cnt[-1]+=1\n",
    "            \"\"\"if not pickup:\n",
    "                reward_shaping -= p_len\n",
    "            reward_shaping -= 0.1 * goal_len\"\"\"\n",
    "            reward += reward_shaping\n",
    "            total_reward_shaped += reward\n",
    "            if epsilon:\n",
    "                q_table[state][action] = q_table[state][action] + alpha*(reward+gamma*np.max(q_table[next_state])-q_table[state][action])\n",
    "            state = next_state\n",
    "            if lst_pickup==False and pickup:\n",
    "                cnt[0]+=1\n",
    "            elif lst_pickup==True and pickup==False:\n",
    "                cnt[1]+=1\n",
    "            if pickup!=ifpickup:\n",
    "                print(pickup,ifpickup)\n",
    "            assert(pickup==ifpickup)\n",
    "\n",
    "\n",
    "        if (epoch+1)%batch_size==0:\n",
    "            cnt = [i/batch_size for i in cnt]\n",
    "            print(f'Epsilon : {epsilon}, average reward : {total_reward/batch_size:.4f}, averaged shaped reward : {total_reward_shaped/batch_size:.4f} Pickup, Drop, Success, Hit wall rate : {cnt}')\n",
    "            print(f'averaged grid size : {averaged[0]/batch_size:.2f}, averaged obstacles : {averaged[1]/batch_size:.2f}')\n",
    "            averaged = [0,0]\n",
    "            cnt = [0,0,0,0]\n",
    "            total_reward = 0\n",
    "            total_reward_shaped = 0\n",
    "        epsilon *= decay_rate #max(epsilon*decay_rate ,epsilon_end)\n",
    "    return q_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oxVEy1uSuNb",
    "outputId": "137a8cf5-0a6b-4e72-9b7c-f5a5c8dddc9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 102/5100 [00:07<02:58, 28.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.9516933769307994, average reward : -11005.0350, averaged shaped reward : -16582.9350 Pickup, Drop, Success, Hit wall rate : [25.41, 25.39, 0.88, 529.8]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 207/5100 [00:10<02:19, 34.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.9052674235521029, average reward : -3913.4050, averaged shaped reward : -5856.1050 Pickup, Drop, Success, Hit wall rate : [20.29, 20.28, 0.99, 199.18]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 308/5100 [00:12<01:27, 54.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.8611062428400729, average reward : -1942.0680, averaged shaped reward : -2981.2680 Pickup, Drop, Success, Hit wall rate : [12.13, 12.13, 1.0, 95.38]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 413/5100 [00:14<01:13, 63.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.8190993535905904, average reward : -1586.8300, averaged shaped reward : -2375.8300 Pickup, Drop, Success, Hit wall rate : [13.24, 13.24, 0.99, 86.83]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 505/5100 [00:16<01:42, 44.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.7791416641455342, average reward : -1405.7840, averaged shaped reward : -2086.4840 Pickup, Drop, Success, Hit wall rate : [12.01, 12.01, 1.0, 79.74]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 607/5100 [00:17<00:55, 81.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.7411332094774175, average reward : -940.5330, averaged shaped reward : -1415.2330 Pickup, Drop, Success, Hit wall rate : [9.67, 9.67, 1.0, 52.77]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 706/5100 [00:19<01:01, 71.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.7049789010996835, average reward : -612.3310, averaged shaped reward : -920.1310 Pickup, Drop, Success, Hit wall rate : [8.74, 8.74, 1.0, 37.49]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 800/5100 [00:20<00:49, 86.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.6705882891769959, average reward : -519.3620, averaged shaped reward : -798.6620 Pickup, Drop, Success, Hit wall rate : [6.19, 6.19, 1.0, 31.42]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 914/5100 [00:21<00:44, 94.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.6378753362403742, average reward : -441.5780, averaged shaped reward : -679.0780 Pickup, Drop, Success, Hit wall rate : [7.61, 7.61, 1.0, 28.2]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1009/5100 [00:22<00:49, 82.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.6067582019410674, average reward : -415.4630, averaged shaped reward : -644.1630 Pickup, Drop, Success, Hit wall rate : [6.01, 6.01, 1.0, 26.01]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1116/5100 [00:23<00:51, 76.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.5771590383046616, average reward : -560.5780, averaged shaped reward : -853.9780 Pickup, Drop, Success, Hit wall rate : [6.79, 6.79, 1.0, 34.43]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1213/5100 [00:24<00:41, 93.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.5490037949732016, average reward : -375.7060, averaged shaped reward : -599.7060 Pickup, Drop, Success, Hit wall rate : [7.05, 7.05, 1.0, 24.19]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1309/5100 [00:25<00:36, 103.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.5222220339480774, average reward : -274.6590, averaged shaped reward : -440.2590 Pickup, Drop, Success, Hit wall rate : [5.58, 5.58, 1.0, 18.14]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1421/5100 [00:27<00:35, 103.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.49674675337021873, average reward : -357.0950, averaged shaped reward : -562.1950 Pickup, Drop, Success, Hit wall rate : [7.29, 7.29, 1.0, 24.2]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1514/5100 [00:28<00:39, 91.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.47251421989671744, average reward : -368.3660, averaged shaped reward : -577.7660 Pickup, Drop, Success, Hit wall rate : [4.3, 4.3, 1.0, 22.36]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 1605/5100 [00:28<00:24, 142.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.44946380925453877, average reward : -226.5960, averaged shaped reward : -371.7960 Pickup, Drop, Success, Hit wall rate : [5.07, 5.07, 1.0, 15.47]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 1712/5100 [00:29<00:26, 130.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.4275378545724137, average reward : -151.4280, averaged shaped reward : -256.5280 Pickup, Drop, Success, Hit wall rate : [4.55, 4.55, 1.0, 11.56]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1812/5100 [00:30<00:28, 114.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.4066815021114777, average reward : -167.9050, averaged shaped reward : -282.8050 Pickup, Drop, Success, Hit wall rate : [4.7, 4.7, 1.0, 12.59]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1920/5100 [00:31<00:23, 136.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.38684257403372235, average reward : -99.1010, averaged shaped reward : -178.6010 Pickup, Drop, Success, Hit wall rate : [3.38, 3.38, 1.0, 8.01]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2025/5100 [00:32<00:26, 114.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.3679714378649446, average reward : -224.3770, averaged shaped reward : -365.5770 Pickup, Drop, Success, Hit wall rate : [4.8, 4.8, 1.0, 15.72]\n",
      "averaged grid size : 5.00, averaged obstacles : 11.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2121/5100 [00:33<00:27, 107.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.35002088232561296, average reward : -185.6280, averaged shaped reward : -309.1280 Pickup, Drop, Success, Hit wall rate : [5.08, 5.08, 1.0, 13.03]\n",
      "averaged grid size : 5.00, averaged obstacles : 11.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2221/5100 [00:34<00:24, 119.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.33294599921901236, average reward : -109.9060, averaged shaped reward : -210.4060 Pickup, Drop, Success, Hit wall rate : [4.75, 4.75, 1.0, 8.21]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2324/5100 [00:35<00:21, 131.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.3167040710811749, average reward : -128.8860, averaged shaped reward : -220.5860 Pickup, Drop, Success, Hit wall rate : [2.85, 2.85, 1.0, 9.28]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2408/5100 [00:36<00:26, 102.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.3012544643115281, average reward : -128.8140, averaged shaped reward : -225.3140 Pickup, Drop, Success, Hit wall rate : [3.43, 3.43, 1.0, 9.1]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2519/5100 [00:37<00:23, 111.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.2865585275168893, average reward : -149.3500, averaged shaped reward : -253.9500 Pickup, Drop, Success, Hit wall rate : [2.73, 2.73, 1.0, 10.0]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2628/5100 [00:37<00:18, 137.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.2725794948144954, average reward : -64.2520, averaged shaped reward : -122.3520 Pickup, Drop, Success, Hit wall rate : [2.02, 2.02, 1.0, 5.84]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 2730/5100 [00:38<00:16, 141.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.2592823938521472, average reward : -64.6600, averaged shaped reward : -128.2600 Pickup, Drop, Success, Hit wall rate : [2.8, 2.8, 1.0, 6.1]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2808/5100 [00:39<00:17, 134.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.2466339583153596, average reward : -28.4630, averaged shaped reward : -66.0630 Pickup, Drop, Success, Hit wall rate : [1.96, 1.96, 1.0, 4.61]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2915/5100 [00:39<00:14, 150.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.23460254470262715, average reward : -62.4990, averaged shaped reward : -120.5990 Pickup, Drop, Success, Hit wall rate : [2.03, 2.03, 1.0, 5.88]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3013/5100 [00:40<00:17, 119.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.22315805316059978, average reward : -43.1960, averaged shaped reward : -89.9960 Pickup, Drop, Success, Hit wall rate : [1.99, 1.99, 1.0, 4.74]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3106/5100 [00:41<00:16, 124.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.21227185218111316, average reward : -62.8540, averaged shaped reward : -114.9540 Pickup, Drop, Success, Hit wall rate : [1.86, 1.86, 1.0, 6.1]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3214/5100 [00:42<00:13, 135.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.20191670697168435, average reward : -47.1210, averaged shaped reward : -97.5210 Pickup, Drop, Success, Hit wall rate : [2.34, 2.34, 1.0, 5.28]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 3317/5100 [00:43<00:12, 140.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.19206671132027073, average reward : -4.8570, averaged shaped reward : -31.7570 Pickup, Drop, Success, Hit wall rate : [1.47, 1.47, 1.0, 2.75]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3417/5100 [00:43<00:11, 151.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.1826972227838353, average reward : -2.3120, averaged shaped reward : -31.0120 Pickup, Drop, Success, Hit wall rate : [1.38, 1.38, 1.0, 2.28]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3511/5100 [00:44<00:11, 135.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.1737848010385734, average reward : -9.8940, averaged shaped reward : -39.5940 Pickup, Drop, Success, Hit wall rate : [1.76, 1.76, 1.0, 3.41]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3622/5100 [00:45<00:10, 146.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.1653071492375671, average reward : -12.3810, averaged shaped reward : -48.1810 Pickup, Drop, Success, Hit wall rate : [2.19, 2.19, 1.0, 3.0]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3718/5100 [00:46<00:11, 123.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.15724305822915946, average reward : -18.9420, averaged shaped reward : -53.0420 Pickup, Drop, Success, Hit wall rate : [1.73, 1.73, 1.0, 3.59]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 3820/5100 [00:46<00:09, 138.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.14957235349649245, average reward : -24.2800, averaged shaped reward : -60.5800 Pickup, Drop, Success, Hit wall rate : [1.73, 1.73, 1.0, 3.91]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3918/5100 [00:47<00:08, 139.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.14227584468546683, average reward : -24.9540, averaged shaped reward : -65.4540 Pickup, Drop, Success, Hit wall rate : [2.53, 2.53, 1.0, 3.9]\n",
      "averaged grid size : 5.00, averaged obstacles : 8.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 4028/5100 [00:48<00:07, 135.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.13533527759485164, average reward : -36.4610, averaged shaped reward : -79.3610 Pickup, Drop, Success, Hit wall rate : [1.61, 1.61, 1.0, 4.01]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 4130/5100 [00:49<00:07, 136.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.12873328850843568, average reward : -18.3630, averaged shaped reward : -51.3630 Pickup, Drop, Success, Hit wall rate : [1.19, 1.19, 1.0, 3.0]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 4222/5100 [00:49<00:07, 122.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.12245336075496815, average reward : -18.7580, averaged shaped reward : -51.5580 Pickup, Drop, Success, Hit wall rate : [1.31, 1.31, 1.0, 3.02]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4303/5100 [00:50<00:06, 129.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.11647978338721439, average reward : 15.8760, averaged shaped reward : -1.1240 Pickup, Drop, Success, Hit wall rate : [1.57, 1.57, 1.0, 1.77]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4412/5100 [00:51<00:07, 90.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.11079761187674808, average reward : -69.8890, averaged shaped reward : -130.6890 Pickup, Drop, Success, Hit wall rate : [3.46, 3.45, 0.99, 6.34]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 4520/5100 [00:52<00:05, 114.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.10539263072614893, average reward : 6.8650, averaged shaped reward : -13.2350 Pickup, Drop, Success, Hit wall rate : [1.58, 1.58, 1.0, 2.17]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4616/5100 [00:53<00:03, 124.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.10025131790506973, average reward : -16.5540, averaged shaped reward : -47.6540 Pickup, Drop, Success, Hit wall rate : [2.21, 2.21, 1.0, 3.8]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4709/5100 [00:54<00:02, 141.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.09536081102119956, average reward : 0.4010, averaged shaped reward : -18.7990 Pickup, Drop, Success, Hit wall rate : [1.26, 1.26, 1.0, 2.62]\n",
      "averaged grid size : 5.00, averaged obstacles : 11.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4818/5100 [00:54<00:02, 132.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.09070887514149145, average reward : -7.4600, averaged shaped reward : -40.2600 Pickup, Drop, Success, Hit wall rate : [2.15, 2.14, 0.99, 2.42]\n",
      "averaged grid size : 5.00, averaged obstacles : 10.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4930/5100 [00:55<00:01, 146.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.08628387218314981, average reward : -17.9560, averaged shaped reward : -47.0560 Pickup, Drop, Success, Hit wall rate : [1.51, 1.51, 1.0, 3.54]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 5005/5100 [00:56<00:00, 106.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0.082074731797801, average reward : -3.6150, averaged shaped reward : -29.6150 Pickup, Drop, Success, Hit wall rate : [1.3, 1.3, 0.99, 1.99]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5100/5100 [00:58<00:00, 86.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon : 0, average reward : -40.7610, averaged shaped reward : -40.7610 Pickup, Drop, Success, Hit wall rate : [0.92, 0.84, 0.84, 0.0]\n",
      "averaged grid size : 5.00, averaged obstacles : 9.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = SimpleTaxiEnv()\n",
    "q_table = tabular_q_learning(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaVsGr6fbI7l"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "q_table_dict = dict(q_table)  # Convert to regular dict\n",
    "q_table_dict_list = {k: v.tolist() for k, v in q_table_dict.items()}  # Convert numpy arrays to lists\n",
    "with open('q_table.pkl', 'wb') as f:\n",
    "    pickle.dump(q_table_dict_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1yAJ9k3vWNPX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "911\n"
     ]
    }
   ],
   "source": [
    "print(len(q_table_dict.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXo_X3thVos1"
   },
   "source": [
    "# 測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def Testing(env):\n",
    "    import pickle\n",
    "    from collections import defaultdict\n",
    "    with open('q_table.pkl', 'rb') as f:\n",
    "        print('load')\n",
    "        loaded_dict = pickle.load(f)\n",
    "    q_table = defaultdict(lambda: np.zeros(6), loaded_dict)  # Replace 0 with your default value\n",
    "    print(len(q_table))\n",
    "    #print('len of q_table',len(q_table.keys()))\n",
    "    global stations, candidates_p,candidates_goal, pickup, goal_id,last_action,last_record_action\n",
    "    stations = [[0,0] for _ in range(4)]\n",
    "    candidates_p = [i for i in stations]\n",
    "    candidates_goal = [i for i in stations]\n",
    "    goal_id = -1\n",
    "    pickup=False\n",
    "    action_size = 6\n",
    "    last_action = None\n",
    "    last_record_action = None\n",
    "    #q_table = defaultdict(lambda :np.zeros(action_size))\n",
    "    pickup_id = 4\n",
    "    drop_id = 5\n",
    "    ifpickup=False\n",
    "    p_loc = (0,0)\n",
    "    def cmp(a,b):\n",
    "        if a==b:\n",
    "            return 0\n",
    "        return 1 if a<b else -1\n",
    "            \n",
    "    def get_state_obs(obs,action,last_action=None):\n",
    "        global stations,pickup,candidates_p,candidates_goal\n",
    "        #print(candidates_p)\n",
    "        taxi_row, taxi_col, stations[0][0], stations[0][1] , stations[1][0], stations[1][1],stations[2][0],stations[2][1],stations[3][0],stations[3][1],obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = obs\n",
    "        agent_pos = (taxi_row,taxi_col)\n",
    "        if action==None:\n",
    "            # initialize\n",
    "            candidates_goal = [tuple(i) for i in stations]\n",
    "            candidates_p = [tuple(i) for i in stations]\n",
    "            pickup=False\n",
    "        if passenger_look:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        else:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        if destination_look:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        else:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        if action==pickup_id and not pickup and agent_pos in candidates_p:\n",
    "            pickup = True\n",
    "            candidates_p = []\n",
    "        elif action == drop_id and pickup:\n",
    "            pickup=False\n",
    "            candidates_p.append(agent_pos)\n",
    "        cmp_pos = (0,0)\n",
    "        if not pickup:\n",
    "            cmp_pos = candidates_p[0]\n",
    "        else:\n",
    "            cmp_pos = candidates_goal[0]\n",
    "        passenger_look = passenger_look and agent_pos in candidates_p\n",
    "        destination_look = destination_look and agent_pos in candidates_goal\n",
    "        real_look = passenger_look if not pickup else destination_look\n",
    "        relative_pos = (cmp(agent_pos[0],cmp_pos[0]),cmp(agent_pos[1],cmp_pos[1]))\n",
    "        return (relative_pos,pickup, real_look, (obstacle_north,obstacle_south,obstacle_east,obstacle_west),last_action)\n",
    "\n",
    "    def get_action(obs):\n",
    "        # TODO: Train your own agent\n",
    "        # HINT: If you're using a Q-table, consider designing a custom key based on `obs` to store useful information.\n",
    "        # NOTE: Keep in mind that your Q-table may not cover all possible states in the testing environment.\n",
    "        #       To prevent crashes, implement a fallback strategy for missing keys.\n",
    "        #       Otherwise, even if your agent performs well in training, it may fail during testing.\n",
    "        global last_action,last_record_action\n",
    "        state = get_state_obs(obs,last_action,last_record_action)\n",
    "        action_name = ['Move North','Move South','Move East','Move West','Pick Up','Drop Off']\n",
    "        if state not in q_table.keys():\n",
    "            #print(state)\n",
    "            print(state)\n",
    "            assert(0)\n",
    "            action = np.random.randint(action_size)\n",
    "        else:\n",
    "            #print(state,action_name[np.argmax(q_table[state])])\n",
    "            action = np.argmax(q_table[state])\n",
    "        last_action = action\n",
    "        if action in [0,1,2,3]:\n",
    "            last_record_action = action\n",
    "        #q_table[state][action] = q_table[state][action] + 0.089487*(-0.1+0.89487*np.max(q_table[state])-q_table[state][action])\n",
    "        return action # Choose a random action\n",
    "        # You can submit this random agent to evaluate the performance of a purely random strategy.\n",
    "    Total_reward=0\n",
    "    for i in tqdm(range(100)):\n",
    "        grid_size = np.random.randint(5,11)\n",
    "        obstacle_size = np.random.randint(grid_size*grid_size)\n",
    "        obs,_ = env.reset()\n",
    "        obs,_,_ = obs\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        stations = [[0,0] for _ in range(4)]\n",
    "        candidates_p = [i for i in stations]\n",
    "        candidates_goal = [i for i in stations]\n",
    "        goal_id = -1\n",
    "        pickup=False\n",
    "        action_size = 6\n",
    "        pickup_id = 4\n",
    "        drop_id = 5\n",
    "        last_action = None\n",
    "        last_record_action = None\n",
    "        while not done:\n",
    "            action = get_action(obs)\n",
    "            obs,reward,done,_ = env.step(action)\n",
    "            obs,_,_ = obs\n",
    "            total_reward += reward\n",
    "        Total_reward+=total_reward\n",
    "        print(f'grid_size : {env.grid_size}, obstacle_size : {len(env.obstacles)}, total_reward : {total_reward}')\n",
    "    print(f'average : {Total_reward/100}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load\n",
      "911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:03, 25.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 3, total_reward : 46.9\n",
      "grid_size : 9, obstacle_size : 38, total_reward : -510.0000000000452\n",
      "grid_size : 7, obstacle_size : 18, total_reward : -510.0000000000452\n",
      "grid_size : 7, obstacle_size : 6, total_reward : 48.9\n",
      "grid_size : 9, obstacle_size : 10, total_reward : 46.699999999999996\n",
      "grid_size : 8, obstacle_size : 28, total_reward : 48.8\n",
      "grid_size : 5, obstacle_size : 0, total_reward : 48.0\n",
      "grid_size : 5, obstacle_size : 7, total_reward : 46.699999999999996\n",
      "grid_size : 6, obstacle_size : 4, total_reward : 48.1\n",
      "grid_size : 6, obstacle_size : 26, total_reward : 48.9\n",
      "grid_size : 5, obstacle_size : 17, total_reward : 49.3\n",
      "grid_size : 10, obstacle_size : 13, total_reward : 47.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:00<00:01, 48.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 9, obstacle_size : 50, total_reward : -510.0000000000452\n",
      "grid_size : 10, obstacle_size : 35, total_reward : -510.0000000000452\n",
      "grid_size : 8, obstacle_size : 42, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 7, total_reward : 49.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:00<00:02, 30.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 8, obstacle_size : 44, total_reward : 47.599999999999994\n",
      "grid_size : 5, obstacle_size : 12, total_reward : 49.4\n",
      "grid_size : 7, obstacle_size : 32, total_reward : -510.0000000000452\n",
      "grid_size : 8, obstacle_size : 6, total_reward : -510.0000000000452\n",
      "grid_size : 9, obstacle_size : 18, total_reward : 47.699999999999996\n",
      "grid_size : 10, obstacle_size : 28, total_reward : -510.0000000000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:00<00:02, 28.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 7, obstacle_size : 33, total_reward : -510.0000000000452\n",
      "grid_size : 9, obstacle_size : 44, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 7, total_reward : -510.0000000000452\n",
      "grid_size : 5, obstacle_size : 15, total_reward : 49.199999999999996\n",
      "grid_size : 7, obstacle_size : 41, total_reward : 49.1\n",
      "grid_size : 6, obstacle_size : 20, total_reward : -510.0000000000452\n",
      "grid_size : 8, obstacle_size : 17, total_reward : 47.699999999999996\n",
      "grid_size : 5, obstacle_size : 7, total_reward : 48.6\n",
      "grid_size : 6, obstacle_size : 0, total_reward : 46.8\n",
      "grid_size : 10, obstacle_size : 10, total_reward : -510.0000000000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:01<00:02, 28.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 9, obstacle_size : 53, total_reward : 48.1\n",
      "grid_size : 7, obstacle_size : 27, total_reward : 48.8\n",
      "grid_size : 9, obstacle_size : 24, total_reward : -510.0000000000452\n",
      "grid_size : 9, obstacle_size : 53, total_reward : 48.1\n",
      "grid_size : 8, obstacle_size : 48, total_reward : 48.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:01<00:02, 27.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 9, obstacle_size : 47, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 5, total_reward : 48.4\n",
      "grid_size : 6, obstacle_size : 23, total_reward : 49.1\n",
      "grid_size : 6, obstacle_size : 21, total_reward : 48.699999999999996\n",
      "grid_size : 5, obstacle_size : 11, total_reward : 48.6\n",
      "grid_size : 7, obstacle_size : 37, total_reward : 48.8\n",
      "grid_size : 7, obstacle_size : 25, total_reward : -510.0000000000452\n",
      "grid_size : 5, obstacle_size : 5, total_reward : -510.0000000000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:01<00:02, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 79, total_reward : 49.199999999999996\n",
      "grid_size : 9, obstacle_size : 47, total_reward : -510.0000000000452\n",
      "grid_size : 9, obstacle_size : 27, total_reward : -520.0000000000474\n",
      "grid_size : 6, obstacle_size : 23, total_reward : 49.199999999999996\n",
      "grid_size : 6, obstacle_size : 17, total_reward : 38.7\n",
      "grid_size : 8, obstacle_size : 44, total_reward : 48.0\n",
      "grid_size : 8, obstacle_size : 12, total_reward : 48.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:01<00:01, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 8, obstacle_size : 48, total_reward : 48.0\n",
      "grid_size : 9, obstacle_size : 64, total_reward : 46.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:02<00:02, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 9, obstacle_size : 58, total_reward : 48.0\n",
      "grid_size : 9, obstacle_size : 47, total_reward : 48.1\n",
      "grid_size : 5, obstacle_size : 14, total_reward : 47.5\n",
      "grid_size : 6, obstacle_size : 22, total_reward : 48.1\n",
      "grid_size : 10, obstacle_size : 62, total_reward : 48.699999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:02<00:01, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 72, total_reward : 46.599999999999994\n",
      "grid_size : 5, obstacle_size : 17, total_reward : 49.0\n",
      "grid_size : 5, obstacle_size : 16, total_reward : 48.4\n",
      "grid_size : 10, obstacle_size : 83, total_reward : -510.0000000000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:02<00:01, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 5, obstacle_size : 11, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 22, total_reward : 49.199999999999996\n",
      "grid_size : 6, obstacle_size : 7, total_reward : 48.9\n",
      "grid_size : 8, obstacle_size : 45, total_reward : 48.699999999999996\n",
      "grid_size : 7, obstacle_size : 21, total_reward : 48.1\n",
      "grid_size : 5, obstacle_size : 6, total_reward : 38.7\n",
      "grid_size : 10, obstacle_size : 1, total_reward : -510.0000000000452\n",
      "grid_size : 9, obstacle_size : 8, total_reward : 48.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:03<00:01, 18.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 77, total_reward : 48.5\n",
      "grid_size : 5, obstacle_size : 14, total_reward : 47.699999999999996\n",
      "grid_size : 8, obstacle_size : 24, total_reward : 48.3\n",
      "grid_size : 5, obstacle_size : 14, total_reward : 48.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:03<00:00, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 78, total_reward : 45.4\n",
      "grid_size : 5, obstacle_size : 6, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 21, total_reward : 46.599999999999994\n",
      "grid_size : 5, obstacle_size : 17, total_reward : 48.9\n",
      "grid_size : 10, obstacle_size : 48, total_reward : -510.0000000000452\n",
      "grid_size : 10, obstacle_size : 12, total_reward : 49.199999999999996\n",
      "grid_size : 6, obstacle_size : 14, total_reward : -510.0000000000452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:03<00:00, 22.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 6, obstacle_size : 6, total_reward : -510.0000000000452\n",
      "grid_size : 10, obstacle_size : 51, total_reward : 48.5\n",
      "grid_size : 6, obstacle_size : 22, total_reward : 48.0\n",
      "grid_size : 5, obstacle_size : 14, total_reward : 48.9\n",
      "grid_size : 7, obstacle_size : 39, total_reward : 48.3\n",
      "grid_size : 5, obstacle_size : 6, total_reward : -510.0000000000452\n",
      "grid_size : 6, obstacle_size : 23, total_reward : 49.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [00:03<00:00, 33.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 10, obstacle_size : 34, total_reward : 48.5\n",
      "grid_size : 6, obstacle_size : 9, total_reward : 48.699999999999996\n",
      "grid_size : 9, obstacle_size : 10, total_reward : -510.0000000000452\n",
      "grid_size : 7, obstacle_size : 10, total_reward : 47.0\n",
      "grid_size : 8, obstacle_size : 9, total_reward : 47.8\n",
      "grid_size : 6, obstacle_size : 22, total_reward : 48.699999999999996\n",
      "grid_size : 8, obstacle_size : 11, total_reward : -510.0000000000452\n",
      "grid_size : 8, obstacle_size : 48, total_reward : -510.0000000000452\n",
      "grid_size : 8, obstacle_size : 9, total_reward : 48.199999999999996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 24.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_size : 7, obstacle_size : 37, total_reward : 48.3\n",
      "grid_size : 8, obstacle_size : 45, total_reward : 46.5\n",
      "average : -119.52500000001356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "env = SimpleTaxiEnv()\n",
    "Testing(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSxQEFroMcJw"
   },
   "source": [
    "# Policy base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nP4NtkKwMi1s"
   },
   "outputs": [],
   "source": [
    "def tabular_policy_learning(env,episodes=5000, alpha=0.1, gamma=0.999):\n",
    "\n",
    "    global stations, candidates_p,candidates_goal, pickup\n",
    "    stations = [[0,0] for _ in range(4)]\n",
    "    candidates_p = [i for i in stations]\n",
    "    candidates_goal = [i for i in stations]\n",
    "    pickup=False\n",
    "    action_size = 6\n",
    "    policy_table = defaultdict(lambda :np.zeros(action_size))\n",
    "    pickup_id = 4\n",
    "    drop_id = 5\n",
    "    ifpickup=False\n",
    "    p_loc = (0,0)\n",
    "    def softmax(x):\n",
    "        \"\"\"✅ Compute softmax values for an array.\"\"\"\n",
    "        exp_x = np.exp(x - np.max(x))  # Numeric stability\n",
    "        return exp_x / exp_x.sum()\n",
    "    def get_state_obs(obs,action):\n",
    "        global stations,pickup,candidates_p,candidates_goal\n",
    "        #print(candidates_p)\n",
    "        obstacles = [0 for _ in range(5)]\n",
    "        taxi_row, taxi_col, stations[0][0], stations[0][1] , stations[1][0], stations[1][1],stations[2][0],stations[2][1],stations[3][0],stations[3][1],obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = obs\n",
    "        agent_pos = (taxi_row,taxi_col)\n",
    "        if action==None:\n",
    "            # initialize\n",
    "            candidates_goal = [tuple(i) for i in stations]\n",
    "            candidates_p = [tuple(i) for i in stations]\n",
    "            pickup=False\n",
    "        if passenger_look:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        else:\n",
    "            #print('before p',candidates_p)\n",
    "            candidates_p = [ tuple(x) for x in candidates_p if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after p',candidates_p)\n",
    "        if destination_look:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) <=1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        else:\n",
    "            #print('before g',candidates_goal)\n",
    "            candidates_goal = [ tuple(x) for x in candidates_goal if abs(x[0]-agent_pos[0])+abs(x[1]-agent_pos[1]) >1 ]\n",
    "            #print('after g',candidates_goal)\n",
    "        if action==pickup_id and not pickup and agent_pos in candidates_p:\n",
    "            pickup = True\n",
    "            candidates_p = []\n",
    "        elif action == drop_id and pickup:\n",
    "            pickup=False\n",
    "            candidates_p = [agent_pos]\n",
    "        return (pickup, len(candidates_p), len(candidates_goal), passenger_look, destination_look, (obstacle_north,obstacle_south,obstacle_east,obstacle_west))\n",
    "    \"\"\"\n",
    "    if action == 0 :  # Move Down\n",
    "        next_row += 1\n",
    "    elif action == 1:  # Move Up\n",
    "        next_row -= 1\n",
    "    elif action == 2:  # Move Right\n",
    "        next_col += 1\n",
    "    elif action == 3:  # Move Left\n",
    "        next_col -= 1\n",
    "    \"\"\"\n",
    "    station_size = 4\n",
    "    total_reward = 0\n",
    "    total_reward_shaped = 0\n",
    "    cnt = [0,0,0]\n",
    "    averaged = [0,0]\n",
    "    batch_size = 100\n",
    "\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(episodes+600)):\n",
    "        if epoch >= episodes:\n",
    "            epsilon = 0\n",
    "        grid_size = np.random.randint(5,11)\n",
    "        obstacle_size = np.random.randint(grid_size*grid_size)\n",
    "        obs,_ = env.reset()\n",
    "        averaged[0]+=env.grid_size\n",
    "        averaged[1]+=len(env.obstacles)\n",
    "        obs,ifpickup,p_loc = obs\n",
    "        done = False\n",
    "        state = get_state_obs(obs,action=None)\n",
    "        steps=0\n",
    "        action_l=[]\n",
    "        success = False\n",
    "        has_pickup=False\n",
    "        trajectory = []\n",
    "        while not done:\n",
    "            \"\"\"if state[-1]!=(0,0,0,0):\n",
    "              print(state[-1])\"\"\"\n",
    "            action = np.random.choice(action_size,p=softmax(policy_table[state]))\n",
    "            lst_pickup = pickup\n",
    "            obs,reward,done,_ = env.step(action)\n",
    "            obs,ifpickup,p_loc = obs\n",
    "            next_state = get_state_obs(obs,action)\n",
    "            total_reward += reward\n",
    "            if done and reward>0:\n",
    "                cnt[2]+=1\n",
    "            reward_shaping = 0\n",
    "            pickup, p_len, goal_len, _,_ , _ = next_state\n",
    "            if not pickup:\n",
    "                reward_shaping -= 0.01 * (p_len**2)\n",
    "            reward_shaping -= 0.001 * (goal_len**2)\n",
    "            reward += reward_shaping\n",
    "            total_reward_shaped += reward\n",
    "            trajectory.append((state,action,reward))\n",
    "            state = next_state\n",
    "\n",
    "\n",
    "            if lst_pickup==False and pickup:\n",
    "                cnt[0]+=1\n",
    "            elif lst_pickup==True and pickup==False:\n",
    "                cnt[1]+=1\n",
    "            if pickup!=ifpickup:\n",
    "                print(pickup,ifpickup)\n",
    "            assert(pickup==ifpickup)\n",
    "        G = 0\n",
    "        for t in reversed(trajectory):\n",
    "            state,action,reward = t\n",
    "            G = gamma*G + reward\n",
    "            prob = softmax(policy_table[state])\n",
    "            grad=-prob.copy()\n",
    "            grad[action]+=1\n",
    "            policy_table[state] += alpha*G*grad\n",
    "        if (epoch+1)%batch_size==0:\n",
    "            cnt = [i/batch_size for i in cnt]\n",
    "            print(f'Epoch : {epoch}, average reward : {total_reward/batch_size:.4f}, averaged shaped reward : {total_reward_shaped/batch_size:.4f} Pickup, Drop, Success rate : {cnt}')\n",
    "            print(f'averaged grid size : {averaged[0]/batch_size:.2f}, averaged obstacles : {averaged[1]/batch_size:.2f}')\n",
    "            averaged = [0,0]\n",
    "            cnt = [0,0,0]\n",
    "            total_reward = 0\n",
    "            total_reward_shaped = 0\n",
    "    return q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pe7Sg6NarrP"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5600 [00:23<20:15,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 99, average reward : -49416.4780, averaged shaped reward : -49994.6282 Pickup, Drop, Success rate : [0.4, 0.39, 0.01]\n",
      "averaged grid size : 7.27, averaged obstacles : 25.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 200/5600 [00:46<19:44,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 199, average reward : -49989.2000, averaged shaped reward : -50640.5557 Pickup, Drop, Success rate : [0.0, 0.0, 0.0]\n",
      "averaged grid size : 7.32, averaged obstacles : 25.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 283/5600 [01:06<20:02,  4.42it/s]"
     ]
    }
   ],
   "source": [
    "env = SimpleTaxiEnv()\n",
    "policy_table = tabular_policy_learning(env)\n",
    "# save policy table to .pkl\n",
    "policy_dict = dict(policy_table)  # Convert to regular dict\n",
    "with open('policy_table.pkl', 'wb') as f:\n",
    "    pickle.dump(policy_dict, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "vBm02Hg7kQwD",
    "ioWeQB4DTncX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
